

# TODO: remember that we're gonna have it be that rules defined prior to the
#       first '[lexer/parser] section:' syntax are considered to be in an
#       implicit lexer section which exists prior to any explicit section

lexer section:

    # TODO: w/ our new LL(1) design, take note of how the below KW_*** LPRs
    #       *must* be defined prior to IDENTIFIER, or it'll be the one matched
    #       instead DUE TO THE ORDER

    # keywords

    support END_OF_KW               : -[0-9a-zA-Z_]
                                    | end ;

    KW_LEXER                        : 'lexer' END_OF_KW ;
    KW_PARSER                       : 'parser' END_OF_KW ;
    KW_SECTION                      : 'section' END_OF_KW ;
    KW_SKIP                         : 'skip' END_OF_KW ;
    KW_SUPPORT                      : 'support' END_OF_KW ;
    KW_END                          : 'end' END_OF_KW ;
    KW_ANY                          : 'any' END_OF_KW ;
    KW_TOKEN                        : 'token' END_OF_KW ;
    KW_FAILURE                      : 'failure' END_OF_KW ;
    
    # operators

    OP_PERIOD                       : '.' ;
    OP_COLON                        : ':' ;
    OP_SEMICOLON                    : ';' ;
    OP_VBAR                         : '|' ;
    OP_QUESTION                     : '?' ;
    OP_ASTERISK                     : '*' ;
    OP_PLUS                         : '+' ;
    OP_AMPERSAND                    : '&' ;
    OP_MINUS                        : '-' ;
    OP_TILDE                        : '~' ;
    OP_L_ROUND                      : '(' ;
    OP_R_ROUND                      : ')' ;

    # general

    IDENTIFIER                      : [a-zA-Z_] [0-9a-zA-Z_]* ;

    # TAUL ESCAPE SEQUENCES
    # 
    # \0                <- Null
    # \a				<- Bell (Alert)
    # \b				<- Backspace
    # \f				<- Form Feed
    # \n				<- New Line
    # \r				<- Carriage Return
    # \t				<- Horizontal Tab
    # \v				<- Vertical Tab
    # \'				<- Single Quotation			<- TAUL doesn't need '\"' escape sequence
    # \]				<- Right Square Bracket		<- for charsets
    # \-				<- Minus					<- for ranges in charsets
    # \\				<- Backslash
    # \xhh			    <- Hex Literal (8-bit)
    # \uhhhh            <- Hex Literal (16-bit)
    # \Uhhhhhhhh        <- Hex Literal (32-bit)
    # 
    # escaped characters which do not form any of the above are *literalized*,
    # meaning the opening '\' is simply removed
    # 
    # TAUL doesn't need, and so doesn't support, octal literal escape sequences
    # 
    # TAUL hex literal escape sequences are *case-insensitive*
    #
    # TAUL hex literals which are malformed are interpreted as literalized 'x' chars

    # TODO: maybe make it so that TAUL strings/charsets remove non-visible chars
    #       from string/charset literals (escaped control chars are fine, the problem
    #       arises from the source code containing improperly placed control chars)

    # while semantically illegal, syntactically the closing '\'' is optional so
    # that the compiler can detect malformed literals

    STRING                          : '\'' ( '\\' any | ~[\'\\] )* '\''? ;

    # TAUL will support ANTLR-style ranges in charsets, w/ escaping the '-' within
    # forms like [a-b] being required to interpret the '-' as part of the charset's
    # character set
    # 
    # like ANTLR, an exception is made for charsets like [-abc-], where the '-'
    # characters are at the vary start or vary end of the charset, in which case
    # they are interpreted as part of the character set of the charset, w/out need
    # of escaping them
    # 
    # another little nuance is that in forms where an unescaped '-' is used to form
    # a char range, but the right char of the char range is an unescaped '-', and
    # one not at the vary start/end of the charset, such as in [aA--b], in these
    # cases the right unescaped '-' is allowed to be used to specify the high codepoint
    # of the range, w/out escaping
    # 
    # TODO: wouldn't the two rules above mean that the right char in the char range
    #       is *in general* exempt from needing to be escaped?
    # 
    # '-' chars which are described explicitly in the form '\x2d' or '\x2D' do not
    # form char ranges
    # 
    # TAUL char ranges within charsets will treat escaped chars, in general, as
    # being equivalent to regular chars regarding forming char ranges (eg. [ab\]-\-cd])
    # 
    # TAUL char ranges within charsets will treat forms like [z-a], in which the
    # higher codepoint character appears first, as equivalent to char ranges where
    # they are flipped around (eg. [z-a] -> [a-z])

    # TODO: do our frontend's tests cover case of charset w/ multiple of same char?
    #       and if not, should we make it ambiguous, or auto-resolved for end-user?
    
    # while semantically illegal, syntactically the closing ']' is optional so
    # that the compiler can detect malformed literals

    CHARSET                         : '[' ( '\\' any | ~[\]\\] )* ']'? ;

    skip WHITESPACE                 : [ \t]+ ;
    skip NEWLINE                    : '\n' | '\r' '\n'? ;

    skip COMMENT                    : '#' ~[\r\n]* ;

parser section:

    # TODO: one flaw w/ this grammar is that if a syntax error occurs BETWEEN clauses,
    #       the parser will STOP parsing entirely, as it'll exit the kleene-star, and
    #       then proceed to the 'end', which'll be the thing the error handler will be
    #       skipping tokens until it reaches
    #
    #       in order to properly fix this, we need to add 'shadowing', then have the
    #       final alt of Clause being to a 'Clause_Malformed' non-terminal, which in
    #       turn simply contains 'any' (who's FIRST set will be shadowed), and then w/
    #       this we can then impl the error reporting as a special behaviour which
    #       occurs during Clause_Malformed's eval, rather than a *true* error, but w/
    #       this nevertheless (maybe) addressing the problem we're having, and doing
    #       so in a way that can be generalized to such use cases more broadly

    Spec                            : Clause* end ;

    Clause                          : LexerSection
                                    | ParserSection
                                    | Rule ;
    
    LexerSection                    : KW_LEXER KW_SECTION OP_COLON ;
    ParserSection                   : KW_PARSER KW_SECTION OP_COLON ;

    Rule                            : Rule_Qualifiers Rule_Name OP_COLON Rule_Alts OP_SEMICOLON ;
    Rule_Qualifiers                 : Qualifiers ;
    Rule_Name                       : IDENTIFIER ;
    Rule_Alts                       : Alts ;

    Qualifiers                      : Qualifier* ;
    Qualifier                       : Qualifier_Skip
                                    | Qualifier_Support ;
    Qualifier_Skip                  : KW_SKIP ;
    Qualifier_Support               : KW_SUPPORT ;
    
    # expr precedence (ordered highest to lowest)
    #       (base)
    #       - end
    #       - any
    #       - token
    #       - failure
    #       - string
    #       - charset
    #       - name
    #       - sequence          <- the expr '( abc )', where 'abc' is the nested expr
    #       - lookahead         <- &x
    #       - lookahead-not     <- -x
    #       - not               <- ~x
    #       (suffix)
    #       - optional          <- x?
    #       - kleene-star       <- x*
    #       - kleene-plus       <- x+

    # for this grammar we can seperate our exprs into 'base' and 'suffix',
    # to deal w/ left-recursion related issues, w/ 'suffix' exprs having
    # lower precedence than 'base' exprs

    # not 100% sure how we'd generalize this to the grammar of a more 
    # complex language, but this'll work for TAUL

    Expr                            : Base Suffix* ;
    Expr_NoSuffix                   : Base ;

    Base                            : Primary
                                    | Sequence
                                    | LookAhead
                                    | LookAheadNot
                                    | Not ;
    Suffix                          : Optional_Suffix
                                    | KleeneStar_Suffix
                                    | KleenePlus_Suffix ;

    Primary                         : End
                                    | Any
                                    | Token
                                    | Failure
                                    | String
                                    | Charset
                                    | Name ;

    End                             : KW_END ;
    Any                             : KW_ANY ;
    Token                           : KW_TOKEN ;
    Failure                         : KW_FAILURE ;
    String                          : STRING ;
    Charset                         : CHARSET ;
    Name                            : IDENTIFIER ;

    Sequence                        : OP_L_ROUND Sequence_Alts OP_R_ROUND ;
    Sequence_Alts                   : Alts ;

    LookAhead                       : OP_AMPERSAND Expr_NoSuffix ;
    LookAheadNot                    : OP_MINUS Expr_NoSuffix ;
    Not                             : OP_TILDE Expr_NoSuffix ;

    Optional_Suffix                 : OP_QUESTION ;
    KleeneStar_Suffix               : OP_ASTERISK ;
    KleenePlus_Suffix               : OP_PLUS ;

    # this handles alternation in sequence exprs and toplevel of rule

    Alts                            : Alt ( Alt_Divider Alt )* ;
    Alt_Divider                     : OP_VBAR ;
    Alt                             : Expr* ;

