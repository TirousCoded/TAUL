

#include <gtest/gtest.h>

#include <taul/source_code.h>
#include <taul/source_reader.h>
#include <taul/lexer.h>
#include <taul/parser.h>
#include <taul/taul_gram.h>
#include <taul/load.h>


using namespace taul::string_literals;


// these tests test frontend details about the grammar generated by loading
// the return value of taul::taul_gram, and testing its lexing/parsing 
// behaviour, but not otherwise asserting what taul::taul_gram must return

// take note that 'support' LPRs are considered herein *impl details* and
// have been excluded from the assertions of the tests below


class TAULGramTests : public testing::Test {
protected:

    std::shared_ptr<taul::logger> lgr = nullptr;
    std::optional<taul::grammar> gram;


    void SetUp() override final {
        lgr = taul::make_stderr_logger();
        gram = taul::taul_gram();
    }
};


//TEST_F(TAULGramTests, LoadsSuccessfully) {
//    ASSERT_TRUE(gram);
//}


TEST_F(TAULGramTests, LPRs) {
    ASSERT_TRUE(gram);

    EXPECT_EQ(gram->nonsupport_lprs(), 27);

    ASSERT_TRUE(gram->has_lpr("KW_LEXER"_str));
    ASSERT_TRUE(gram->has_lpr("KW_PARSER"_str));
    ASSERT_TRUE(gram->has_lpr("KW_SECTION"_str));
    ASSERT_TRUE(gram->has_lpr("KW_SKIP"_str));
    ASSERT_TRUE(gram->has_lpr("KW_SUPPORT"_str));
    ASSERT_TRUE(gram->has_lpr("KW_END"_str));
    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("KW_TOKEN"_str));
    ASSERT_TRUE(gram->has_lpr("KW_FAILURE"_str));

    EXPECT_EQ(gram->lpr("KW_LEXER"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_PARSER"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_SECTION"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_SKIP"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_SUPPORT"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_END"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_ANY"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_TOKEN"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("KW_FAILURE"_str)->qualifier(), taul::qualifier::none);

    ASSERT_TRUE(gram->has_lpr("OP_PERIOD"_str));
    ASSERT_TRUE(gram->has_lpr("OP_COLON"_str));
    ASSERT_TRUE(gram->has_lpr("OP_SEMICOLON"_str));
    ASSERT_TRUE(gram->has_lpr("OP_VBAR"_str));
    ASSERT_TRUE(gram->has_lpr("OP_QUESTION"_str));
    ASSERT_TRUE(gram->has_lpr("OP_ASTERISK"_str));
    ASSERT_TRUE(gram->has_lpr("OP_PLUS"_str));
    ASSERT_TRUE(gram->has_lpr("OP_AMPERSAND"_str));
    ASSERT_TRUE(gram->has_lpr("OP_MINUS"_str));
    ASSERT_TRUE(gram->has_lpr("OP_TILDE"_str));
    ASSERT_TRUE(gram->has_lpr("OP_L_ROUND"_str));
    ASSERT_TRUE(gram->has_lpr("OP_R_ROUND"_str));

    EXPECT_EQ(gram->lpr("OP_PERIOD"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_COLON"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_SEMICOLON"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_VBAR"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_QUESTION"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_ASTERISK"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_PLUS"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_AMPERSAND"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_MINUS"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_TILDE"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_L_ROUND"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("OP_R_ROUND"_str)->qualifier(), taul::qualifier::none);

    ASSERT_TRUE(gram->has_lpr("IDENTIFIER"_str));
    ASSERT_TRUE(gram->has_lpr("STRING"_str));
    ASSERT_TRUE(gram->has_lpr("CHARSET"_str));

    EXPECT_EQ(gram->lpr("IDENTIFIER"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("STRING"_str)->qualifier(), taul::qualifier::none);
    EXPECT_EQ(gram->lpr("CHARSET"_str)->qualifier(), taul::qualifier::none);

    ASSERT_TRUE(gram->has_lpr("WHITESPACE"_str));
    ASSERT_TRUE(gram->has_lpr("NEWLINE"_str));
    ASSERT_TRUE(gram->has_lpr("COMMENT"_str));

    EXPECT_EQ(gram->lpr("WHITESPACE"_str)->qualifier(), taul::skip);
    EXPECT_EQ(gram->lpr("NEWLINE"_str)->qualifier(), taul::skip);
    EXPECT_EQ(gram->lpr("COMMENT"_str)->qualifier(), taul::skip);
}

TEST_F(TAULGramTests, PPRs) {
    ASSERT_TRUE(gram);

    EXPECT_EQ(gram->pprs(), 35);

    ASSERT_TRUE(gram->has_ppr("Spec"_str));

    ASSERT_TRUE(gram->has_ppr("Clause"_str));
    
    ASSERT_TRUE(gram->has_ppr("LexerSection"_str));
    ASSERT_TRUE(gram->has_ppr("ParserSection"_str));
    
    ASSERT_TRUE(gram->has_ppr("Rule"_str));
    ASSERT_TRUE(gram->has_ppr("Rule_Qualifiers"_str));
    ASSERT_TRUE(gram->has_ppr("Rule_Name"_str));
    ASSERT_TRUE(gram->has_ppr("Rule_Alts"_str));
    
    ASSERT_TRUE(gram->has_ppr("Qualifiers"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifier"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifier_Skip"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifier_Support"_str));
    
    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Suffix"_str));
    
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    
    ASSERT_TRUE(gram->has_ppr("End"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Token"_str));
    ASSERT_TRUE(gram->has_ppr("Failure"_str));
    ASSERT_TRUE(gram->has_ppr("String"_str));
    ASSERT_TRUE(gram->has_ppr("Charset"_str));
    ASSERT_TRUE(gram->has_ppr("Name"_str));

    ASSERT_TRUE(gram->has_ppr("Sequence"_str));
    ASSERT_TRUE(gram->has_ppr("Sequence_Alts"_str));

    ASSERT_TRUE(gram->has_ppr("LookAhead"_str));
    ASSERT_TRUE(gram->has_ppr("LookAheadNot"_str));
    ASSERT_TRUE(gram->has_ppr("Not"_str));

    ASSERT_TRUE(gram->has_ppr("Optional_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleeneStar_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleenePlus_Suffix"_str));

    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt_Divider"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));
}


#define _SETUP_FOR_LPR(_NAME_) \
ASSERT_TRUE(gram);\
ASSERT_TRUE(gram->has_lpr(_NAME_));\
taul::source_reader reader(""_str);\
taul::lexer lexer(gram.value());\
lexer.bind_source(&reader);\
auto _succeed =\
[&](taul::str input, taul::source_len expected_len) {\
    auto expected = taul::token::normal(gram.value(), _NAME_, 0, expected_len);\
    reader.change_input(input);\
    lexer.reset();\
    auto actual = lexer.next();\
    TAUL_LOG(lgr, "_succeed({}, {})", input, expected_len);\
    EXPECT_EQ(expected, actual);\
    };\
auto _fail =\
[&](taul::str input) {\
    reader.change_input(input);\
    lexer.reset();\
    auto actual = lexer.next();\
    TAUL_LOG(lgr, "_fail({})", input);\
    EXPECT_NE(actual.id, gram->lpr(_NAME_)->id());\
    };\
((void)0)

#define _KW_TEST(_KW_, _LITERAL_, _LEN_) \
TEST_F(TAULGramTests, _KW_) {\
    _SETUP_FOR_LPR(taul::str::lit(#_KW_));\
\
    constexpr taul::source_len len = _LEN_;\
\
    _succeed(_LITERAL_ ""_str, len);\
    _succeed(_LITERAL_ " "_str, len);\
    _succeed(_LITERAL_ "\r\n"_str, len);\
    _succeed(_LITERAL_ "#abc"_str, len);\
    _succeed(_LITERAL_ "?"_str, len);\
\
    _fail(_LITERAL_ "a"_str);\
    _fail(_LITERAL_ "0"_str);\
    _fail(_LITERAL_ "_"_str);\
    _fail(""_str);\
    _fail(" "_str);\
    _fail("abc"_str);\
    _fail("123"_str);\
    _fail("?*&"_str);\
}

_KW_TEST(KW_LEXER, "lexer", 5);
_KW_TEST(KW_PARSER, "parser", 6);
_KW_TEST(KW_SECTION, "section", 7);
_KW_TEST(KW_SKIP, "skip", 4);
_KW_TEST(KW_SUPPORT, "support", 7);
_KW_TEST(KW_END, "end", 3);
_KW_TEST(KW_ANY, "any", 3);
_KW_TEST(KW_TOKEN, "token", 5);
_KW_TEST(KW_FAILURE, "failure", 7);

#define _OP_TEST(_OP_, _LITERAL_) \
TEST_F(TAULGramTests, _OP_) {\
    _SETUP_FOR_LPR(taul::str::lit(#_OP_));\
\
    _succeed(_LITERAL_ ""_str, 1);\
    _succeed(_LITERAL_ " "_str, 1);\
    _succeed(_LITERAL_ "\r\n"_str, 1);\
    _succeed(_LITERAL_ "#abc"_str, 1);\
    _succeed(_LITERAL_ "?"_str, 1);\
    _succeed(_LITERAL_ "a"_str, 1);\
    _succeed(_LITERAL_ "1"_str, 1);\
    _succeed(_LITERAL_ "_"_str, 1);\
\
    _fail(""_str);\
    _fail(" "_str);\
    _fail("a"_str);\
    _fail("1"_str);\
    if (_LITERAL_ ""_str == "?"_str)\
        _fail("&"_str);\
    else\
        _fail("?"_str);\
}

_OP_TEST(OP_PERIOD, "."_str);
_OP_TEST(OP_COLON, ":"_str);
_OP_TEST(OP_SEMICOLON, ";"_str);
_OP_TEST(OP_VBAR, "|"_str);
_OP_TEST(OP_QUESTION, "?"_str);
_OP_TEST(OP_ASTERISK, "*"_str);
_OP_TEST(OP_PLUS, "+"_str);
_OP_TEST(OP_AMPERSAND, "&"_str);
_OP_TEST(OP_MINUS, "-"_str);
_OP_TEST(OP_TILDE, "~"_str);
_OP_TEST(OP_L_ROUND, "("_str);
_OP_TEST(OP_R_ROUND, ")"_str);

TEST_F(TAULGramTests, IDENTIFIER) {
    _SETUP_FOR_LPR("IDENTIFIER"_str);

    _succeed("a"_str, 1);
    _succeed("_"_str, 1);
    _succeed("abc"_str, 3);
    _succeed("defghi"_str, 6);
    _succeed("_abc"_str, 4);
    _succeed("a123"_str, 4);
    _succeed("_123"_str, 4);
    _succeed("abc\r\n"_str, 3);
    _succeed("abc#abc"_str, 3);
    _succeed("abc?"_str, 3);

    _fail(""_str);
    _fail(" "_str);
    _fail("123"_str);
    _fail("?*&"_str);
}

TEST_F(TAULGramTests, STRING) {
    _SETUP_FOR_LPR("STRING"_str);

    _succeed("''"_str, 2);
    _succeed("'abc'"_str, 5);
    _succeed("'123'"_str, 5);
    _succeed("'?*+'"_str, 5);
    _succeed("'\n\f'"_str, 4);
    _succeed("'"_str, 1); // illegal semantically
    _succeed("'abc"_str, 4); // illegal semantically
    _succeed("'123"_str, 4); // illegal semantically
    _succeed("'?*+"_str, 4); // illegal semantically
    _succeed("'\n\f"_str, 3); // illegal semantically
    _succeed("''abc"_str, 2);
    _succeed("''123"_str, 2);
    _succeed("''_"_str, 2);
    _succeed("''\r\n"_str, 2);
    _succeed("''#abc"_str, 2);
    _succeed("''?"_str, 2);

    // escape sequences

    _succeed("'\\0'"_str, 4);
    _succeed("'\\a'"_str, 4);
    _succeed("'\\b'"_str, 4);
    _succeed("'\\f'"_str, 4);
    _succeed("'\\n'"_str, 4);
    _succeed("'\\r'"_str, 4);
    _succeed("'\\t'"_str, 4);
    _succeed("'\\v'"_str, 4);
    _succeed("'\\''"_str, 4);
    _succeed("'\\]'"_str, 4);
    _succeed("'\\-'"_str, 4);
    _succeed("'\\x00'"_str, 6);
    _succeed("'\\x08'"_str, 6);
    _succeed("'\\xff'"_str, 6);
    _succeed("'\\xFa'"_str, 6);
    _succeed("'\\xe4'"_str, 6);
    _succeed("'\\xBD'"_str, 6);
    _succeed("'\\p'"_str, 4); // escaping random char

    _succeed("'\\0"_str, 3); // illegal semantically
    _succeed("'\\a"_str, 3); // illegal semantically
    _succeed("'\\b"_str, 3); // illegal semantically
    _succeed("'\\f"_str, 3); // illegal semantically
    _succeed("'\\n"_str, 3); // illegal semantically
    _succeed("'\\r"_str, 3); // illegal semantically
    _succeed("'\\t"_str, 3); // illegal semantically
    _succeed("'\\v"_str, 3); // illegal semantically
    _succeed("'\\'"_str, 3); // illegal semantically
    _succeed("'\\]"_str, 3); // illegal semantically
    _succeed("'\\-"_str, 3); // illegal semantically
    _succeed("'\\x00"_str, 5); // illegal semantically
    _succeed("'\\x08"_str, 5); // illegal semantically
    _succeed("'\\xff"_str, 5); // illegal semantically
    _succeed("'\\xFa"_str, 5); // illegal semantically
    _succeed("'\\xe4"_str, 5); // illegal semantically
    _succeed("'\\xBD"_str, 5); // illegal semantically
    _succeed("'\\p"_str, 3); // illegal semantically

    _fail(""_str);
    _fail(" "_str);
    _fail("\"\""_str); // no support for double-quotes for literals
    _fail("abc"_str);
    _fail("123"_str);
    _fail("?*&"_str);
}

TEST_F(TAULGramTests, CHARSET) {
    _SETUP_FOR_LPR("CHARSET"_str);

    _succeed("[]"_str, 2);
    _succeed("[abc]"_str, 5);
    _succeed("[123]"_str, 5);
    _succeed("[?*+]"_str, 5);
    _succeed("[\n\f]"_str, 4);
    _succeed("["_str, 1); // illegal semantically
    _succeed("[abc"_str, 4); // illegal semantically
    _succeed("[123"_str, 4); // illegal semantically
    _succeed("[?*+"_str, 4); // illegal semantically
    _succeed("[\n\f"_str, 3); // illegal semantically
    _succeed("[]abc"_str, 2);
    _succeed("[]123"_str, 2);
    _succeed("[]_"_str, 2);
    _succeed("[]\r\n"_str, 2);
    _succeed("[]#abc"_str, 2);
    _succeed("[]?"_str, 2);

    // escape sequences

    _succeed("[\\0]"_str, 4);
    _succeed("[\\a]"_str, 4);
    _succeed("[\\b]"_str, 4);
    _succeed("[\\f]"_str, 4);
    _succeed("[\\n]"_str, 4);
    _succeed("[\\r]"_str, 4);
    _succeed("[\\t]"_str, 4);
    _succeed("[\\v]"_str, 4);
    _succeed("[\\']"_str, 4);
    _succeed("[\\]]"_str, 4);
    _succeed("[\\-]"_str, 4);
    _succeed("[\\x00]"_str, 6);
    _succeed("[\\x08]"_str, 6);
    _succeed("[\\xff]"_str, 6);
    _succeed("[\\xFa]"_str, 6);
    _succeed("[\\xe4]"_str, 6);
    _succeed("[\\xBD]"_str, 6);
    _succeed("[\\p]"_str, 4); // escaping random char

    _succeed("[\\0"_str, 3); // illegal semantically
    _succeed("[\\a"_str, 3); // illegal semantically
    _succeed("[\\b"_str, 3); // illegal semantically
    _succeed("[\\f"_str, 3); // illegal semantically
    _succeed("[\\n"_str, 3); // illegal semantically
    _succeed("[\\r"_str, 3); // illegal semantically
    _succeed("[\\t"_str, 3); // illegal semantically
    _succeed("[\\v"_str, 3); // illegal semantically
    _succeed("[\\'"_str, 3); // illegal semantically
    _succeed("[\\]"_str, 3); // illegal semantically
    _succeed("[\\-"_str, 3); // illegal semantically
    _succeed("[\\x00"_str, 5); // illegal semantically
    _succeed("[\\x08"_str, 5); // illegal semantically
    _succeed("[\\xff"_str, 5); // illegal semantically
    _succeed("[\\xFa"_str, 5); // illegal semantically
    _succeed("[\\xe4"_str, 5); // illegal semantically
    _succeed("[\\xBD"_str, 5); // illegal semantically
    _succeed("[\\p"_str, 3); // illegal semantically

    _fail(""_str);
    _fail(" "_str);
    _fail("abc"_str);
    _fail("123"_str);
    _fail("?*&"_str);
}

TEST_F(TAULGramTests, WHITESPACE) {
    _SETUP_FOR_LPR("WHITESPACE"_str);
    lexer.cut_skip_tokens = false;

    _succeed(" "_str, 1);
    _succeed(" abc"_str, 1);
    _succeed(" 123"_str, 1);
    _succeed(" _"_str, 1);
    _succeed(" \r\n"_str, 1);
    _succeed(" #abc"_str, 1);
    _succeed(" ?"_str, 1);
    _succeed("\t"_str, 1);
    _succeed("\tabc"_str, 1);
    _succeed("\t123"_str, 1);
    _succeed("\t_"_str, 1);
    _succeed("\t\r\n"_str, 1);
    _succeed("\t#abc"_str, 1);
    _succeed("\t?"_str, 1);
    _succeed("  \t \t\t "_str, 7);
    _succeed("  \t \t\t abc"_str, 7);
    _succeed("  \t \t\t 123"_str, 7);
    _succeed("  \t \t\t _"_str, 7);
    _succeed("  \t \t\t \r\n"_str, 7);
    _succeed("  \t \t\t #abc"_str, 7);
    _succeed("  \t \t\t ?"_str, 7);

    _fail(""_str);
    _fail("\r\n"_str);
    _fail("abc"_str);
    _fail("123"_str);
    _fail("?*&"_str);
}

TEST_F(TAULGramTests, NEWLINE) {
    _SETUP_FOR_LPR("NEWLINE"_str);
    lexer.cut_skip_tokens = false;

    _succeed("\r"_str, 1);
    _succeed("\rabc"_str, 1);
    _succeed("\r123"_str, 1);
    _succeed("\r_"_str, 1);
    _succeed("\r\r\n"_str, 1);
    _succeed("\r#abc"_str, 1);
    _succeed("\r?"_str, 1);
    _succeed("\n"_str, 1);
    _succeed("\nabc"_str, 1);
    _succeed("\n123"_str, 1);
    _succeed("\n_"_str, 1);
    _succeed("\n\r\n"_str, 1);
    _succeed("\n#abc"_str, 1);
    _succeed("\n?"_str, 1);
    _succeed("\r\n"_str, 2);
    _succeed("\r\nabc"_str, 2);
    _succeed("\r\n123"_str, 2);
    _succeed("\r\n_"_str, 2);
    _succeed("\r\n\r\n"_str, 2);
    _succeed("\r\n#abc"_str, 2);
    _succeed("\r\n?"_str, 2);

    _fail(""_str);
    _fail(" "_str);
    _fail("\f"_str);
    _fail("abc"_str);
    _fail("123"_str);
    _fail("?*&"_str);
}

TEST_F(TAULGramTests, COMMENT) {
    _SETUP_FOR_LPR("COMMENT"_str);
    lexer.cut_skip_tokens = false;

    _succeed("#"_str, 1);
    _succeed("# abc"_str, 5);
    _succeed("# abcabc"_str, 8);
    _succeed("# abc123"_str, 8);
    _succeed("# abc_"_str, 6);
    _succeed("# abc#abc"_str, 9);
    _succeed("# abc?"_str, 6);
    _succeed("# abc\r"_str, 5); // stop just before newline
    _succeed("# abc\n"_str, 5); // stop just before newline
    _succeed("# abc\r\n"_str, 5); // stop just before newline

    _fail(""_str);
    _fail(" "_str);
    _fail("\r\n"_str);
    _fail("abc"_str);
    _fail("123"_str);
    _fail("?*&"_str);
}


// we're gonna perform our syntax tests *in bulk*, w/ bulk unit tests 
// for collections of PPRs tested at once via an example node tree


#define _SETUP_FOR_PPR(src) \
ASSERT_TRUE(gram);\
taul::source_reader reader(src);\
taul::lexer lexer(gram.value());\
taul::parser parser(gram.value(), lgr);\
lexer.bind_source(&reader);\
parser.bind_source(&lexer);\
parser.reset();\
((void)0)

struct counter final {
    taul::source_pos pos = 0;


    taul::source_pos operator()(taul::source_len progress_by) noexcept {
        pos += progress_by;
        return pos - progress_by;
    }

    taul::source_pos operator()() noexcept {
        return (*this)(0);
    }
};

TEST_F(TAULGramTests, Syntax_EmptySourceFile) {
    taul::source_code input{};

    ASSERT_TRUE(input.add_file(std::filesystem::current_path() / "support\\taul_gram_tests_1.taul", lgr));

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_ppr("Spec"_str));

    counter cntr{};

    cntr(15);

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Spec"_str, cntr())
        //.skip(15)
        .close();

    auto actual = parser.parse("Spec"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_BasicTopLevel) {
    taul::source_code input{};

    ASSERT_TRUE(input.add_file(std::filesystem::current_path() / "support\\taul_gram_tests_2.taul", lgr));

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_LEXER"_str));
    ASSERT_TRUE(gram->has_lpr("KW_PARSER"_str));
    ASSERT_TRUE(gram->has_lpr("KW_SECTION"_str));
    ASSERT_TRUE(gram->has_lpr("KW_SKIP"_str));
    ASSERT_TRUE(gram->has_lpr("KW_SUPPORT"_str));
    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_COLON"_str));
    ASSERT_TRUE(gram->has_lpr("OP_SEMICOLON"_str));

    ASSERT_TRUE(gram->has_ppr("Spec"_str));
    ASSERT_TRUE(gram->has_ppr("Clause"_str));
    ASSERT_TRUE(gram->has_ppr("LexerSection"_str));
    ASSERT_TRUE(gram->has_ppr("ParserSection"_str));
    ASSERT_TRUE(gram->has_ppr("Rule"_str));
    ASSERT_TRUE(gram->has_ppr("Rule_Qualifiers"_str));
    ASSERT_TRUE(gram->has_ppr("Rule_Name"_str));
    ASSERT_TRUE(gram->has_ppr("Rule_Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifiers"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifier"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifier_Skip"_str));
    ASSERT_TRUE(gram->has_ppr("Qualifier_Support"_str));
    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt_Divider"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    taul::parse_tree expected(gram.value());

    cntr(4);

    expected
        .syntactic("Spec"_str, cntr());

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("LexerSection"_str, cntr())
        .lexical("KW_LEXER"_str, cntr(6), 5)
        .lexical("KW_SECTION"_str, cntr(7), 7)
        .lexical("OP_COLON"_str, cntr(9), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(7), 1)
        .close()
        .close();
    
    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(7), 1)
        .close()
        .close();
    
    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Support"_str, cntr())
        .lexical("KW_SUPPORT"_str, cntr(8), 7)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(9), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Support"_str, cntr())
        .lexical("KW_SUPPORT"_str, cntr(8), 7)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Support"_str, cntr())
        .lexical("KW_SUPPORT"_str, cntr(8), 7)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(28), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("ParserSection"_str, cntr())
        .lexical("KW_PARSER"_str, cntr(7), 6)
        .lexical("KW_SECTION"_str, cntr(7), 7)
        .lexical("OP_COLON"_str, cntr(9), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(9), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(30), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Support"_str, cntr())
        .lexical("KW_SUPPORT"_str, cntr(8), 7)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(30), 1)
        .close()
        .close();

    expected
        .syntactic("Clause"_str, cntr())
        .syntactic("Rule"_str, cntr())
        .syntactic("Rule_Qualifiers"_str, cntr())
        .syntactic("Qualifiers"_str, cntr())
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Support"_str, cntr())
        .lexical("KW_SUPPORT"_str, cntr(8), 7)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Skip"_str, cntr())
        .lexical("KW_SKIP"_str, cntr(5), 4)
        .close()
        .close()
        .syntactic("Qualifier"_str, cntr())
        .syntactic("Qualifier_Support"_str, cntr())
        .lexical("KW_SUPPORT"_str, cntr(8), 7)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Rule_Name"_str, cntr())
        .lexical("IDENTIFIER"_str, cntr(2), 1)
        .close()
        .lexical("OP_COLON"_str, cntr(2), 1)
        .syntactic("Rule_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_SEMICOLON"_str, cntr(), 1)
        .close()
        .close();

    expected
        .close();

    auto actual = parser.parse("Spec"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

#define _PRIMARY_EXPR_SYNTAX_TEST(_RULE_, _TKN_RULE_, _LITERAL_, _LITERAL_LEN_)\
TEST_F(TAULGramTests, Syntax_ ## _RULE_) {\
    taul::source_code input{};\
\
    input.add_str(""_str, _LITERAL_ ""_str);\
\
    _SETUP_FOR_PPR(input);\
\
    ASSERT_TRUE(gram->has_lpr(#_TKN_RULE_ ""_str));\
\
    ASSERT_TRUE(gram->has_ppr("Expr"_str));\
    ASSERT_TRUE(gram->has_ppr("Base"_str));\
    ASSERT_TRUE(gram->has_ppr("Primary"_str));\
    ASSERT_TRUE(gram->has_ppr(#_RULE_ ""_str));\
\
    counter cntr{};\
\
    taul::parse_tree expected(gram.value());\
\
    expected\
        .syntactic("Expr"_str, cntr())\
        .syntactic("Base"_str, cntr())\
        .syntactic("Primary"_str, cntr())\
        .syntactic(#_RULE_ ""_str, cntr())\
        .lexical(#_TKN_RULE_ ""_str, cntr(), _LITERAL_LEN_)\
        .close()\
        .close()\
        .close()\
        .close();\
\
    auto actual = parser.parse("Expr"_str);\
\
    TAUL_LOG(lgr, "expected:\n{}", expected);\
    TAUL_LOG(lgr, "actual:\n{}", actual);\
\
    EXPECT_EQ(expected.fmt(), actual.fmt()); /* easier to diagnose problems w/ this */\
}

_PRIMARY_EXPR_SYNTAX_TEST(End, KW_END, "end", 3);
_PRIMARY_EXPR_SYNTAX_TEST(Any, KW_ANY, "any", 3);
_PRIMARY_EXPR_SYNTAX_TEST(Token, KW_TOKEN, "token", 5);
_PRIMARY_EXPR_SYNTAX_TEST(Failure, KW_FAILURE, "failure", 7);
_PRIMARY_EXPR_SYNTAX_TEST(String, STRING, "'hello'", 7);
_PRIMARY_EXPR_SYNTAX_TEST(Charset, CHARSET, "[0-9a-zA-Z_]", 12);
_PRIMARY_EXPR_SYNTAX_TEST(Name, IDENTIFIER, "abc", 3);

TEST_F(TAULGramTests, Syntax_Sequence) {
    taul::source_code input{};

    input.add_str(""_str, "( any )"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_L_ROUND"_str));
    ASSERT_TRUE(gram->has_lpr("OP_R_ROUND"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Sequence"_str));
    ASSERT_TRUE(gram->has_ppr("Sequence_Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Sequence"_str, cntr())
        .lexical("OP_L_ROUND"_str, cntr(2), 1)
        .syntactic("Sequence_Alts"_str, cntr())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .lexical("OP_R_ROUND"_str, cntr(1), 1)
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_LookAhead) {
    taul::source_code input{};

    input.add_str(""_str, "&any"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_AMPERSAND"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("LookAhead"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("LookAhead"_str, cntr())
        .lexical("OP_AMPERSAND"_str, cntr(1), 1)
        .syntactic("Expr_NoSuffix"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_LookAheadNot) {
    taul::source_code input{};

    input.add_str(""_str, "-any"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_MINUS"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("LookAheadNot"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("LookAheadNot"_str, cntr())
        .lexical("OP_MINUS"_str, cntr(1), 1)
        .syntactic("Expr_NoSuffix"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_Not) {
    taul::source_code input{};

    input.add_str(""_str, "~any"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_TILDE"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Not"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Not"_str, cntr())
        .lexical("OP_TILDE"_str, cntr(1), 1)
        .syntactic("Expr_NoSuffix"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_Suffixes) {
    taul::source_code input{};

    input.add_str(""_str, "any?*+"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_QUESTION"_str));
    ASSERT_TRUE(gram->has_lpr("OP_ASTERISK"_str));
    ASSERT_TRUE(gram->has_lpr("OP_PLUS"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Optional_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleeneStar_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleenePlus_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("Optional_Suffix"_str, cntr())
        .lexical("OP_QUESTION"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleeneStar_Suffix"_str, cntr())
        .lexical("OP_ASTERISK"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleenePlus_Suffix"_str, cntr())
        .lexical("OP_PLUS"_str, cntr(1), 1)
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_Suffixes_NotablePrecedence_A) {
    taul::source_code input{};

    input.add_str(""_str, "&any?*+"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_QUESTION"_str));
    ASSERT_TRUE(gram->has_lpr("OP_ASTERISK"_str));
    ASSERT_TRUE(gram->has_lpr("OP_PLUS"_str));
    ASSERT_TRUE(gram->has_lpr("OP_AMPERSAND"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("LookAhead"_str));
    ASSERT_TRUE(gram->has_ppr("Optional_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleeneStar_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleenePlus_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("LookAhead"_str, cntr())
        .lexical("OP_AMPERSAND"_str, cntr(1), 1)
        .syntactic("Expr_NoSuffix"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("Optional_Suffix"_str, cntr())
        .lexical("OP_QUESTION"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleeneStar_Suffix"_str, cntr())
        .lexical("OP_ASTERISK"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleenePlus_Suffix"_str, cntr())
        .lexical("OP_PLUS"_str, cntr(1), 1)
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_Suffixes_NotablePrecedence_B) {
    taul::source_code input{};

    input.add_str(""_str, "-any?*+"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_QUESTION"_str));
    ASSERT_TRUE(gram->has_lpr("OP_ASTERISK"_str));
    ASSERT_TRUE(gram->has_lpr("OP_PLUS"_str));
    ASSERT_TRUE(gram->has_lpr("OP_MINUS"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("LookAheadNot"_str));
    ASSERT_TRUE(gram->has_ppr("Optional_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleeneStar_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleenePlus_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("LookAheadNot"_str, cntr())
        .lexical("OP_MINUS"_str, cntr(1), 1)
        .syntactic("Expr_NoSuffix"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("Optional_Suffix"_str, cntr())
        .lexical("OP_QUESTION"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleeneStar_Suffix"_str, cntr())
        .lexical("OP_ASTERISK"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleenePlus_Suffix"_str, cntr())
        .lexical("OP_PLUS"_str, cntr(1), 1)
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_Suffixes_NotablePrecedence_C) {
    taul::source_code input{};

    input.add_str(""_str, "~any?*+"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_QUESTION"_str));
    ASSERT_TRUE(gram->has_lpr("OP_ASTERISK"_str));
    ASSERT_TRUE(gram->has_lpr("OP_PLUS"_str));
    ASSERT_TRUE(gram->has_lpr("OP_TILDE"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Expr_NoSuffix"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Not"_str));
    ASSERT_TRUE(gram->has_ppr("Optional_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleeneStar_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("KleenePlus_Suffix"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Not"_str, cntr())
        .lexical("OP_TILDE"_str, cntr(1), 1)
        .syntactic("Expr_NoSuffix"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(3), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("Optional_Suffix"_str, cntr())
        .lexical("OP_QUESTION"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleeneStar_Suffix"_str, cntr())
        .lexical("OP_ASTERISK"_str, cntr(1), 1)
        .close()
        .close()
        .syntactic("Suffix"_str, cntr())
        .syntactic("KleenePlus_Suffix"_str, cntr())
        .lexical("OP_PLUS"_str, cntr(1), 1)
        .close()
        .close()
        .close();

    auto actual = parser.parse("Expr"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

TEST_F(TAULGramTests, Syntax_Alts) {
    taul::source_code input{};

    input.add_str(""_str, "any any | any | |"_str);

    _SETUP_FOR_PPR(input);

    ASSERT_TRUE(gram->has_lpr("KW_ANY"_str));
    ASSERT_TRUE(gram->has_lpr("OP_VBAR"_str));

    ASSERT_TRUE(gram->has_ppr("Expr"_str));
    ASSERT_TRUE(gram->has_ppr("Base"_str));
    ASSERT_TRUE(gram->has_ppr("Primary"_str));
    ASSERT_TRUE(gram->has_ppr("Any"_str));
    ASSERT_TRUE(gram->has_ppr("Alts"_str));
    ASSERT_TRUE(gram->has_ppr("Alt_Divider"_str));
    ASSERT_TRUE(gram->has_ppr("Alt"_str));

    counter cntr{};

    auto expected =
        taul::parse_tree(gram.value())
        .syntactic("Alts"_str, cntr())
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .syntactic("Alt_Divider"_str, cntr())
        .lexical("OP_VBAR"_str, cntr(2), 1)
        .close()
        .syntactic("Alt"_str, cntr())
        .syntactic("Expr"_str, cntr())
        .syntactic("Base"_str, cntr())
        .syntactic("Primary"_str, cntr())
        .syntactic("Any"_str, cntr())
        .lexical("KW_ANY"_str, cntr(4), 3)
        .close()
        .close()
        .close()
        .close()
        .close()
        .syntactic("Alt_Divider"_str, cntr())
        .lexical("OP_VBAR"_str, cntr(2), 1)
        .close()
        .syntactic("Alt"_str, cntr())
        .close()
        .syntactic("Alt_Divider"_str, cntr())
        .lexical("OP_VBAR"_str, cntr(1), 1)
        .close()
        .syntactic("Alt"_str, cntr())
        .close()
        .close();

    auto actual = parser.parse("Alts"_str);

    TAUL_LOG(lgr, "expected:\n{}", expected);
    TAUL_LOG(lgr, "actual:\n{}", actual);

    EXPECT_EQ(expected.fmt(), actual.fmt()); // easier to diagnose problems w/ this
}

